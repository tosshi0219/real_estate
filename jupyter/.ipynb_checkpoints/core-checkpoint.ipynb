{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which mode do you use \"learning\" or \"inference\"?inference\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'data_version' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-95a5307b57b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'inference'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#spec取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mcrawler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCrawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mpage_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrawler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_page_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0murls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrawler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'data_version' and 'target'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/toshio/project/real_estate')\n",
    "from src.crawler import Crawler\n",
    "from src.preprocess_purchase import PreprocessPurchase\n",
    "from src.inference import Inference\n",
    "from src.learning_purchase import Learning\n",
    "from src.postprocess import Postprocess,Email\n",
    "\n",
    "mode=input('which mode do you use \"learning\" or \"inference\"?')\n",
    "\n",
    "if mode == 'learning':\n",
    "    data_version=input('which data do you learn? ex.new, original, 20180722 etc.')\n",
    "    if data_version=='new':\n",
    "        #新たにspec取得\n",
    "        data_version=datetime.now().strftime(\"%Y%m%d\")\n",
    "        crawler=Crawler()\n",
    "        page_num=crawler.get_page_num()\n",
    "        urls=crawler.get_urls(page_num)\n",
    "        pages=crawler.get_pages(urls)\n",
    "        crawler.save_pages(pages)\n",
    "        bodys=crawler.get_bodys(pages)\n",
    "        bids=crawler.get_bids(bodys)  \n",
    "        bids=crawler.delete_duplication(bids)    \n",
    "        links=crawler.get_links(bids)\n",
    "        link_pages=crawler.get_link_pages(links)\n",
    "        crawler.save_link_pages(link_pages)\n",
    "        link_bodys=crawler.get_link_bodys(link_pages)\n",
    "        specs=crawler.crawlers(link_bodys)\n",
    "        crawler.save_specs(specs)\n",
    "        crawler.output(specs)\n",
    "\n",
    "    #preprocess\n",
    "    prep=Preprocess(mode)\n",
    "    spec=prep.load_spec()\n",
    "    spec=prep.pre_price(spec)\n",
    "    spec=prep.pre_bid(spec)\n",
    "    spec=prep.pre_transportation(spec)\n",
    "    spec=prep.pre_land(spec)\n",
    "    spec=prep.pre_area(spec)\n",
    "    spec=prep.pre_structure(spec)\n",
    "    spec=prep.pre_age(spec)\n",
    "    spec=prep.pre_floor(spec)\n",
    "    spec=prep.pre_direction(spec)\n",
    "    spec=prep.pre_mcost(spec)\n",
    "    spec=prep.pre_rcost(spec)\n",
    "    spec=prep.encode_cat_to_label(spec)\n",
    "    spec=prep.pre_outlier(spec)\n",
    "    spec=prep.del_bid(spec)\n",
    "    prep.save_spec(spec)\n",
    "\n",
    "    #learning\n",
    "    learning=Learning(data_version)\n",
    "    gs=learning.xgb_learning(spec)\n",
    "    learning.show_results(gs)\n",
    "    learning.save_model(gs)\n",
    "#     spec_all,spec_bad=learning.check_prediction(spec)\n",
    "#     learning.save_prediction(spec_all)\n",
    "\n",
    "elif mode == 'inference':\n",
    "    #spec取得\n",
    "    data_version=datetime.now().strftime(\"%Y%m%d\") \n",
    "    model_version=input('which model do you use? ex.original, 20180722 etc.')\n",
    "    crawler=Crawler(data_version, model_version)\n",
    "    page_num=crawler.get_page_num()\n",
    "    urls=crawler.get_urls(page_num)\n",
    "    pages=crawler.get_pages(urls)\n",
    "    crawler.save_pages(pages)\n",
    "#         pages=crawler.load_pages(load_date)\n",
    "    bodys=crawler.get_bodys(pages)\n",
    "    bids=crawler.get_bids(bodys)  \n",
    "    bids=crawler.delete_duplication(bids)    \n",
    "    links=crawler.get_links(bids)\n",
    "    link_pages=crawler.get_link_pages(links)\n",
    "    crawler.save_link_pages(link_pages)\n",
    "#         link_pages=crawler.load_link_pages(load_date)\n",
    "    link_bodys=crawler.get_link_bodys(link_pages)\n",
    "    specs=crawler.crawlers(link_bodys)\n",
    "    crawler.save_specs(specs)\n",
    "#         specs=crawler.load_specs(load_date)\n",
    "    crawler.output(specs)\n",
    "\n",
    "    #preprocess        \n",
    "    prep = Preprocess(mode)\n",
    "    spec=prep.load_spec()\n",
    "    spec=prep.pre_price(spec)\n",
    "    spec=prep.pre_bid(spec)\n",
    "    spec=prep.pre_transportation(spec)\n",
    "    spec=prep.pre_land(spec)\n",
    "    spec=prep.pre_area(spec)\n",
    "    spec=prep.pre_structure(spec)\n",
    "    spec=prep.pre_age(spec)\n",
    "    spec=prep.pre_floor(spec)\n",
    "    spec=prep.pre_direction(spec)\n",
    "    spec=prep.pre_mcost(spec)\n",
    "    spec=prep.pre_rcost(spec)\n",
    "    spec=prep.encode_cat_to_label(spec)\n",
    "    prep.save_spec(spec)    \n",
    "\n",
    "    #inference\n",
    "    inf=Inference(data_version,model_version)\n",
    "    spec=inf.load_prep_spec()\n",
    "    treasure=inf.inference(spec)\n",
    "    inf.save_treasure(treasure)\n",
    "\n",
    "    #postprocess\n",
    "    post=Postprocess(data_version,model_version)\n",
    "    spec=post.load_result()\n",
    "    spec=post.decode(spec)\n",
    "    body=post.urls(spec)\n",
    "    em=Email()\n",
    "    msg=em.create_message(body)\n",
    "    em.send(msg)\n",
    "\n",
    "else:\n",
    "    print('input \"learning\" or \"inference\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
