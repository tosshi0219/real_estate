{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = 'http://www.fudousan.or.jp/system/?act=l&type=12&pref=13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page = requests.get(url0)\n",
    "soup=BeautifulSoup(page.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodys=[]\n",
    "bodys.append(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#検索件数を取得し、ページ数を計算する\n",
    "for i in bodys[0].find_all('th'):\n",
    "    if (i.text).find('検索結果')!=-1:\n",
    "        end=(i.text).find('件')\n",
    "        num=int(i.text[6:end])\n",
    "\n",
    "page_num=num//20+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#検索全ページのurlを取得\n",
    "urls=[]\n",
    "for i in range(2,page_num):\n",
    "    urls.append('http://www.fudousan.or.jp/system/?act=l&type=12&pref=13&n=20&p={}&v=off,s='.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#全ページのhtmlを5秒おきに取得\n",
    "pages=[]\n",
    "# for i in range(len(urls)):\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    time.sleep(5)\n",
    "    page_i=requests.get(urls[i])\n",
    "    pages.append(page_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180716\n"
     ]
    }
   ],
   "source": [
    "#検索を実行した時刻を取得\n",
    "searched_date=datetime.now().strftime(\"%Y%m%d\")\n",
    "print(searched_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得したページのhtmlをpickle化\n",
    "with open('storage/pages_{}.pickle'.format(searched_date),'wb') as f:\n",
    "    pickle.dump(pages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htmlをpickle化したものをロード\n",
    "load_date='20180716'\n",
    "with open('storage/pages_{}.pickle'.format(load_date),'rb') as f:\n",
    "    pages=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#htmlをパースして、bodyを取り出す\n",
    "for i in pages:\n",
    "    soup_i=BeautifulSoup(i.text,\"lxml\")\n",
    "    bodys.append(soup_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ページ内のbit番号を取得\n",
    "bids=[]\n",
    "for bd in bodys:\n",
    "    for i,tag in enumerate(bd.find_all('a')):\n",
    "        if (tag.get('href')!=None):\n",
    "            bid_st=(tag.get('href')).find('bid=')\n",
    "            bid_len=(tag.get('href'))[bid_st:].find('&')\n",
    "            if bid_st != -1:\n",
    "                bid_num=tag.get('href')[bid_st+4:bid_st+bid_len]\n",
    "                bids.append(bid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重複したbit番号を削除\n",
    "bids=list(set(bids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各物件のlinkをリストに格納\n",
    "links=[]\n",
    "for i in bids:\n",
    "    links.append('http://www.fudousan.or.jp/system/?act=d&type=12&pref=13&n=20&p=1&v=on&s=&bid={}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各物件画面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "#各物件のhtmlを五秒おきに取得\n",
    "link_pages=[]\n",
    "for i in range(len(links)):\n",
    "    print(i)\n",
    "    time.sleep(5)\n",
    "    link_page_i=requests.get(links[i])\n",
    "    link_pages.append(link_page_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得した物件ページのhtmlをpickle化\n",
    "with open('storage/link_pages_{}.pickle'.format(searched_date),'wb') as f:\n",
    "    pickle.dump(link_pages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htmlをpickle化したものをロード\n",
    "with open('storage/link_pages_{}.pickle'.format(load_date),'rb') as f:\n",
    "    link_pages=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "#htmlをパースして、bodyを取り出す\n",
    "link_bodys=[]\n",
    "cnt=0\n",
    "for i in link_pages:\n",
    "    cnt+=1\n",
    "    print(cnt)\n",
    "    link_soup_i=BeautifulSoup(i.text,\"lxml\")\n",
    "    link_bodys.append(link_soup_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "#物件情報の取得\n",
    "specs=[]\n",
    "\n",
    "for i,link_bd in enumerate(link_bodys):\n",
    "    print(i)\n",
    "    keys=[]\n",
    "    values=[]\n",
    "    \n",
    "    for s in link_bd.find_all('span'):\n",
    "        if (s.text).find('価格') != -1:\n",
    "            price=s.text.split()[1][:-2]\n",
    "            keys.append('price')\n",
    "            values.append(price)\n",
    "        \n",
    "    for t in link_bd.find_all('tr'):\n",
    "        if (t.find('th')!=None) & (t.find('td')!=None):\n",
    "            th_tags=t.find_all('th')\n",
    "            td_tags=t.find_all('td')\n",
    "            for i in range(len(th_tags)):\n",
    "                keys.append(th_tags[i].text)\n",
    "                values.append(td_tags[i].text)\n",
    "    spec=dict(zip(keys, values))\n",
    "    specs.append(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得した物件ページのspecをpickle化\n",
    "# with open('storage/specs_{}.pickle'.format(searched_date),'wb') as f:\n",
    "#     pickle.dump(specs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaryに保存したデータをcsvに出力する\n",
    "df_specs=pd.DataFrame(specs)\n",
    "col=['price',\n",
    "        '詳細情報\\xa0',\n",
    "        '所在地',\n",
    "        '交通',\n",
    "        '㎡／坪単価',\n",
    "        '専有面積',\n",
    "        '間取り',\n",
    "        '間取り内訳',\n",
    "        '物件種目',\n",
    "        '築年月',\n",
    "        '構造',\n",
    "        '階数',\n",
    "        '向き',\n",
    "        'バルコニー等面積',\n",
    "        '駐車場',\n",
    "        '設備',\n",
    "        '総戸数',\n",
    "        '販売戸数',\n",
    "        '敷地面積',\n",
    "        '敷地の権利形態',\n",
    "        '借地料および借地期間',\n",
    "        '敷金',\n",
    "        '保証金',\n",
    "        '管理形態',\n",
    "        '管理会社',\n",
    "        '管理費等',\n",
    "        '修繕積立金',\n",
    "        '修繕積立基金',\n",
    "        '施設費用/償却費',\n",
    "        '用途地域',\n",
    "        'その他費用',\n",
    "        '施工会社',\n",
    "        '現況',\n",
    "        '引き渡し時期',\n",
    "        '国土法届出',\n",
    "        '工事完了年月',\n",
    "        '備考１',\n",
    "        '備考2',\n",
    "        '特記',\n",
    "        '取引態様',\n",
    "        '情報登録日',\n",
    "        '次回更新予定日',\n",
    "        '物件HP',\n",
    "        '不動産会社詳細']\n",
    "\n",
    "output=pd.DataFrame(columns=col)\n",
    "for i,c in enumerate(col):\n",
    "    output[output.columns[i]]=df_specs[c]\n",
    "output.to_csv('intermediate_data/spec_{}.csv'.format(searched_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 44)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
